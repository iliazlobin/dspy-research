{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# !huggingface-cli login --token $HUGGING_FACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'long_text': 'Perplexity, the AI search engine startup, is a hot property at the moment. TechCrunch has learned that the company is currently raising at least $250 million more at a valuation of between $2.5 billion and $3 billion. The news comes on the heels of two other big fundraises that have seen the company’s valuation leapfrog in the last four months: In January, the company raised nearly $74 million at a valuation of $540 million (up from $121 million in April 2023).'},\n",
       " {'long_text': 'And at the beginning of March, the company closed funding on a valuation of $1 billion, with CEO Aravind Srinivas clarifying on Twitter today that the amount raised was roughly $63 million. Those two reported rounds are not the full story. We understand from multiple sources close to the company that Perplexity is raising a further round of at least $250 million to capitalize on the attention it’s getting in the market.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.retrieve.you_rm import YouRM\n",
    "\n",
    "# colbert_retriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "you_retriever = YouRM()\n",
    "results = you_retriever.forward('What is the latest confirmed valuation of Perplexity. Include date, raised amount, the series name of the funding round and VCs')\n",
    "results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.retrieve.you_rm import YouRM\n",
    "\n",
    "gpt3_model = dspy.OpenAI('gpt-3.5-turbo-0125', max_tokens=1000)\n",
    "\n",
    "dspy.configure(lm=gpt3_model, rm=you_retriever)\n",
    "# dspy.configure(lm=gpt3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip\n"
     ]
    }
   ],
   "source": [
    "%%script echo skip\n",
    "\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "\n",
    "dataset = HotPotQA(train_seed=1, train_size=200, eval_seed=2023, dev_size=300, test_size=0)\n",
    "trainset = [x.with_inputs('question') for x in dataset.train[0:150]]\n",
    "valset = [x.with_inputs('question') for x in dataset.train[150:200]]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "# show an example datapoint; it's just a question-answer pair\n",
    "trainset\n",
    "# trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Example({'question': 'What is the latest confirmed valuation of Perplexity. Include date, raised amount, the series name of the funding round and VCs', 'company': 'Perplexity', 'valuation': '$1B', 'date': 'April 2024', 'raised': '$62.7M', 'round': 'Series B1', 'VCs': 'Daniel Gross'}) (input_keys={'company'})]\n",
      "[Example({'question': 'What is the latest confirmed valuation of Stability AI. Include date, raised amount, the series name of the funding round and VCs', 'company': 'Stability AI', 'valuation': '$1B', 'date': 'September 2022', 'raised': '$101M', 'round': '', 'VCs': 'Coatue, Lightspeed Venture Partners'}) (input_keys={'company'})]\n",
      "[Example({'question': 'What is the latest confirmed valuation of Runway. Include date, raised amount, the series name of the funding round and VCs', 'company': 'Runway'}) (input_keys={'company'})]\n"
     ]
    }
   ],
   "source": [
    "from dspy.primitives import Example\n",
    "\n",
    "trainset = [\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Perplexity. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Perplexity\",\n",
    "            \"valuation\": \"$1B\",\n",
    "            \"date\": \"April 2024\",\n",
    "            \"raised\": \"$62.7M\",\n",
    "            \"round\": \"Series B1\",\n",
    "            \"VCs\": \"Daniel Gross\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Cohere. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Cohere\",\n",
    "            \"valuation\": \"$2.2B\",\n",
    "            \"date\": \"June 2023\",\n",
    "            \"raised\": \"$62.7M\",\n",
    "            \"round\": \"Series C\",\n",
    "            \"VCs\": \"Inovia Capital\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Anthropic. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Anthropic\",\n",
    "            \"valuation\": \"$18.4B\",\n",
    "            \"date\": \"December 2023\",\n",
    "            \"raised\": \"$750M\",\n",
    "            \"round\": \"Series C\",\n",
    "            \"VCs\": \"Menlo Ventures\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Groq. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Groq\",\n",
    "            \"valuation\": \"$1B\",\n",
    "            \"date\": \"February 2024\",\n",
    "            \"raised\": \"$149.9M\",\n",
    "            \"round\": \"Series C\",\n",
    "            \"VCs\": \"Tiger Global, D1 Capital\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Weaviate. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Weaviate\",\n",
    "            \"valuation\": \"$200M\",\n",
    "            \"date\": \"April 2023\",\n",
    "            \"raised\": \"$50M\",\n",
    "            \"round\": \"Series B\",\n",
    "            \"VCs\": \"Index Ventures\",\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "trainset = [x.with_inputs(\"company\") for x in trainset]\n",
    "print(trainset[:1])\n",
    "\n",
    "from dspy.primitives import Example\n",
    "\n",
    "devset = [\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Stability AI. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Stability AI\",\n",
    "            \"valuation\": \"$1B\",\n",
    "            \"date\": \"September 2022\",\n",
    "            \"raised\": \"$101M\",\n",
    "            \"round\": \"\",\n",
    "            \"VCs\": \"Coatue, Lightspeed Venture Partners\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Databricks. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Databricks\",\n",
    "            \"valuation\": \"$43B\",\n",
    "            \"date\": \"September 2023\",\n",
    "            \"raised\": \"$500M\",\n",
    "            \"round\": \"Series I\",\n",
    "            \"VCs\": \"T. Rowe Price Associates\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Hugging Face. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Hugging Face\",\n",
    "            \"valuation\": \"$4.5B\",\n",
    "            \"date\": \"August 2023\",\n",
    "            \"raised\": \"$235M\",\n",
    "            \"round\": \"Series D\",\n",
    "            \"VCs\": \"Salesforce Ventures\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Cognition. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Cognition\",\n",
    "            \"valuation\": \"$2B\",\n",
    "            \"date\": \"Aipril 2024\",\n",
    "            \"raised\": \"$175M\",\n",
    "            \"round\": \"Series A\",\n",
    "            \"VCs\": \"Founders Fund\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Mistral AI. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Mistral AI\",\n",
    "            \"valuation\": \"$2B\",\n",
    "            \"date\": \"December 2023\",\n",
    "            \"raised\": \"$415M\",\n",
    "            \"round\": \"Series A\",\n",
    "            \"VCs\": \"Lightspeed Venture Partners, General Catalyst\",\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "devset = [x.with_inputs(\"company\") for x in devset]\n",
    "print(devset[:1])\n",
    "\n",
    "from dspy.primitives import Example\n",
    "\n",
    "someset = [\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Runway. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Runway\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of ElevenLabs. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"ElevenLabs\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Pika. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"Pika\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of Writer. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"AI21 Labs\",\n",
    "        }\n",
    "    ),\n",
    "    Example(\n",
    "        {\n",
    "            \"question\": \"What is the latest confirmed valuation of AI21 Labs. Include date, raised amount, the series name of the funding round and VCs\",\n",
    "            \"company\": \"AI21 Labs\",\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "someset = [x.with_inputs(\"company\") for x in someset]\n",
    "print(someset[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1)])\n",
    "# predictor = dspy.Predict(\"input -> valuation, date\", tools=[dspy.Retrieve(k=1)])\n",
    "\n",
    "predictor = dspy.Predict(\"company -> valuation, date, raised, round, VCs\")\n",
    "# predictor = dspy.Predict(\"company -> valuation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'question': 'What is the latest confirmed valuation of Stability AI. Include date, raised amount, the series name of the funding round and VCs', 'company': 'Stability AI', 'valuation': '$1B', 'date': 'September 2022', 'raised': '$101M', 'round': '', 'VCs': 'Coatue, Lightspeed Venture Partners'}) (input_keys={'company'})\n",
      "Prediction(\n",
      "    valuation='$10 million',\n",
      "    date='January 15, 2022',\n",
      "    raised='$5 million',\n",
      "    round='Series A\\n\\nVCs: Sequoia Capital, Accel Partners',\n",
      "    VCs='Sequoia Capital, Accel Partners'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# test plain\n",
    "\n",
    "print(devset[0])\n",
    "result = predictor(company = devset[0].company)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssessValuation(dspy.Signature):\n",
    "    \"\"\"Assess the prediction of the valuation amount based on actual (reference) data provided.\"\"\"\n",
    "\n",
    "    predicted_valuation = dspy.InputField(desc=\"Predicted company valuation\")\n",
    "    actual_valuation = dspy.InputField(desc=\"Actual company valuation\")\n",
    "    assessment = dspy.OutputField(desc=\"Valid or Invalid\")\n",
    "\n",
    "\n",
    "class AssessDate(dspy.Signature):\n",
    "    \"\"\"Assess the prediction of the valuation date based on actual (reference) data provided.\"\"\"\n",
    "\n",
    "    predicted_date = dspy.InputField(\n",
    "        desc=\"Predicted date when the valuation was confirmed\"\n",
    "    )\n",
    "    actual_date = dspy.InputField(desc=\"Actual date when the valuation was confirmed\")\n",
    "    assessment = dspy.OutputField(desc=\"Valid or Invalid\")\n",
    "\n",
    "\n",
    "def metric(reference, pred, trace=None):\n",
    "    with dspy.context(lm=gpt3_model):\n",
    "        valuation_assessment = dspy.Predict(AssessValuation)(\n",
    "            predicted_valuation=pred.valuation, actual_valuation=reference.valuation\n",
    "        )\n",
    "        date_assessment = dspy.Predict(AssessDate)(\n",
    "            predicted_date=pred.date, actual_date=reference.date\n",
    "        )\n",
    "\n",
    "    # Explained: split()[0]: take the first word off of \"Invalid\\n\\nThe predicted valuation of $10....\"\n",
    "    valuation_score, date_score = (\n",
    "        1 if m.assessment.split()[0].lower() == \"valid\" else 0\n",
    "        for m in [valuation_assessment, date_assessment]\n",
    "    )\n",
    "    print(f\"{reference.company}: valuation: {valuation_assessment}, {valuation_score}, data: {date_assessment}, {date_score}\")\n",
    "    score = valuation_score + date_score\n",
    "    return score / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 5  (0.0): 100%|██████████| 5/5 [00:00<00:00, 285.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability AI: valuation: Prediction(\n",
      "    assessment=\"Invalid\\n\\nThe predicted valuation of $10 million is significantly lower than the actual valuation of $1 billion. This assessment is invalid as it is not an accurate prediction of the company's valuation.\"\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of the valuation date was significantly off, being several months later than the actual date. This indicates that the prediction was not accurate or reliable.'\n",
      "), 0\n",
      "Databricks: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $28 billion is significantly lower than the actual valuation of $43 billion. This indicates that the prediction was not accurate and did not reflect the true value of the company.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction was significantly off, being over a year and a half later than the actual valuation date. This suggests that the prediction was not accurate or reliable.'\n",
      "), 0\n",
      "Hugging Face: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $1 billion is significantly lower than the actual valuation of $4.5 billion. This indicates that the prediction was not accurate and did not reflect the true value of the company.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction was significantly off, being almost 2 years later than the actual date. This shows that the prediction was not accurate and therefore invalid.'\n",
      "), 0\n",
      "Cognition: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $10 million is significantly lower than the actual valuation of $2 billion. This assessment is invalid as the prediction was off by a large margin.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of the valuation date was significantly off, being more than 2 years later than the actual date. This indicates that the prediction was not accurate or reliable.'\n",
      "), 0\n",
      "Mistral AI: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $10 million is significantly lower than the actual valuation of $2 billion. This assessment is invalid as the prediction was off by a large margin.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction was significantly off, being over a year later than the actual date. This indicates that the prediction was not accurate or reliable.'\n",
      "), 0\n",
      "Average Metric: 0.0 / 5  (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate = Evaluate(devset=devset[:], metric=metric, num_threads=1, display_progress=True, display_table=False, display=True)\n",
    "evaluate(predictor, devset=devset[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyValuation(dspy.Signature):\n",
    "    \"\"\"Company's latest confirmed valuation.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"Contains relevant facts about the company\")\n",
    "    company = dspy.InputField(desc=\"The name of the company\")\n",
    "    valuation = dspy.OutputField(desc=\"Company valuation\")\n",
    "    date = dspy.OutputField(desc=\"When the valuation was confirmed\")\n",
    "    raised = dspy.OutputField(desc=\"Amount raised in the latest funding round\")\n",
    "    round = dspy.OutputField(desc=\"the series name of the funding round (Series A, Series B, etc)\")\n",
    "    VCs = dspy.OutputField(desc=\"Venture capitalists involved in the latest funding round\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve()\n",
    "        # self.generate = dspy.ChainOfThought(CompanyValuation)\n",
    "        self.generate = dspy.Predict(CompanyValuation)\n",
    "\n",
    "    def forward(self, company):\n",
    "        context = self.retrieve(company).passages\n",
    "        prediction = self.generate(context=context, company=company)\n",
    "        return prediction\n",
    "        # return dspy.Prediction(context=context, prediction=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'question': 'What is the latest confirmed valuation of Stability AI. Include date, raised amount, the series name of the funding round and VCs', 'company': 'Stability AI', 'valuation': '$1B', 'date': 'September 2022', 'raised': '$101M', 'round': '', 'VCs': 'Coatue, Lightspeed Venture Partners'}) (input_keys={'company'})\n",
      "Prediction(\n",
      "    valuation='$500 million',\n",
      "    date='October 2021',\n",
      "    raised='$50 million',\n",
      "    round='Series B\\n\\nVCs: XYZ Ventures, ABC Capital, DEF Partners',\n",
      "    VCs='XYZ Ventures, ABC Capital, DEF Partners'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# test RAG\n",
    "\n",
    "rag_predictor = RAG()\n",
    "\n",
    "print(devset[0])\n",
    "result=rag_predictor(devset[0].company)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):  20%|██        | 1/5 [00:02<00:11,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability AI: valuation: Prediction(\n",
      "    assessment=\"Invalid\\n\\nThe predicted valuation of $500 million is significantly lower than the actual valuation of $1 billion. This prediction is invalid as it underestimates the company's value.\"\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of October 2021 was incorrect as the actual date of September 2022 is significantly later. This indicates that the prediction was not accurate.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):  40%|████      | 2/5 [00:05<00:07,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databricks: valuation: Prediction(\n",
      "    assessment=\"Invalid\\n\\nThe predicted valuation of $38 billion was lower than the actual valuation of $43 billion. This indicates that the prediction was not accurate and underestimated the company's value.\"\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of the valuation date was incorrect as the actual date when the valuation was confirmed was earlier than the predicted date.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 3  (0.0):  60%|██████    | 3/5 [00:08<00:06,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation was close to the actual valuation, but it was slightly underestimated. This suggests that the prediction was not entirely accurate, although it was in the right ballpark.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of the valuation date was significantly off, being more than a year later than the actual date. This makes the prediction invalid.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 4  (0.0):  80%|████████  | 4/5 [00:13<00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognition: valuation: Prediction(\n",
      "    assessment=\"Invalid\\n\\nThe predicted valuation of $100 million is significantly lower than the actual valuation of $2 billion. This assessment is invalid as it is not an accurate prediction of the company's valuation.\"\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted date of October 15, 2024, does not align with the actual date of April 2024. The prediction was off by several months, making it invalid.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.5 / 5  (10.0): 100%|██████████| 5/5 [00:18<00:00,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral AI: valuation: Prediction(\n",
      "    assessment=\"Invalid\\n\\nThe predicted valuation of $2.5 billion was higher than the actual valuation of $2 billion. This indicates that the prediction was inaccurate and overestimated the company's value.\"\n",
      "), 0, data: Prediction(\n",
      "    assessment='Valid'\n",
      "), 1\n",
      "Average Metric: 0.5 / 5  (10.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate = Evaluate(devset=devset[:], metric=metric, num_threads=1, display_progress=True, display_table=False, display=True)\n",
    "evaluate(rag_predictor, devset=devset[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:11,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there is no predicted valuation provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction was not provided, so it cannot be assessed.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:06<00:09,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there is no predicted valuation provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there was no predicted date provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:10<00:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $6B was significantly lower than the actual valuation of $18.4B. This indicates that the prediction was not accurate and therefore invalid.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of the valuation date was incorrect as it was expected to be in September 2023 but was actually confirmed in December 2023.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:15<00:04,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq: valuation: Prediction(\n",
      "    assessment='Valid'\n",
      "), 1, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted date of April 2021 was significantly off from the actual date of February 2024. This assessment is invalid as the prediction was not accurate.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:19<00:00,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaviate: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there is no predicted valuation provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there was no predicted date provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0\n",
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch, BootstrapFewShot\n",
    "\n",
    "# acher_settings={}, max_bootstrapped_demos=4, max_labeled_demos=16, max_rounds=1, max_errors=\n",
    "# teleprompter = BootstrapFewShotWithRandomSearch(\n",
    "teleprompter = BootstrapFewShot(\n",
    "    metric=metric,\n",
    "    # num_threads=2,\n",
    "    # num_candidate_programs=3,\n",
    "    # max_labeled_demos=3,\n",
    ")\n",
    "\n",
    "compiled_rag_predictor = teleprompter.compile(\n",
    "    rag_predictor,\n",
    "    trainset=trainset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):  20%|██        | 1/5 [00:04<00:19,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability AI: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nWithout a predicted valuation to compare to the actual valuation of $1B, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nSince the predicted date was not provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):  40%|████      | 2/5 [00:08<00:13,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databricks: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $1B is significantly lower than the actual valuation of $43B. This prediction is invalid as it is not reflective of the true value of the company.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThe prediction of the valuation date in February 2021 was significantly off as the actual date when the valuation was confirmed was in September 2023. This prediction was invalid due to the large discrepancy between the predicted and actual dates.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 3  (0.0):  60%|██████    | 3/5 [00:12<00:07,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there is no predicted valuation provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there was no predicted date provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 4  (0.0):  80%|████████  | 4/5 [00:15<00:03,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognition: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nSince there is no predicted valuation provided, it is impossible to assess the accuracy of the prediction.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Invalid\\n\\nThere is no predicted date provided to assess the accuracy of the valuation date.'\n",
      "), 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.5 / 5  (10.0): 100%|██████████| 5/5 [00:18<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral AI: valuation: Prediction(\n",
      "    assessment='Invalid\\n\\nThe predicted valuation of $1B was significantly lower than the actual valuation of $2B. This indicates that the prediction was inaccurate and invalid.'\n",
      "), 0, data: Prediction(\n",
      "    assessment='Valid'\n",
      "), 1\n",
      "Average Metric: 0.5 / 5  (10.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "evaluate = Evaluate(devset=devset[:], metric=metric, num_threads=1, display_progress=True, display_table=False, display=True)\n",
    "evaluate(compiled_rag_predictor, devset=devset[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
